# File Upload Limits
spring.servlet.multipart.max-file-size=50MB
spring.servlet.multipart.max-request-size=50MB

# ===================================================================
# RAG Java Project Configuration
# ===================================================================

# ----------------------------------------
# SERVER CONFIGURATION
# ----------------------------------------
server.port=8080

# ----------------------------------------
# DATABASE CONFIGURATION (PostgreSQL with pgvector)
# ----------------------------------------
spring.datasource.url=${DB_URL:jdbc:postgresql://localhost:5432/postgres?characterEncoding=UTF-8}
spring.datasource.username=${DB_USERNAME:postgres}
spring.datasource.password=${DB_PASSWORD:postgres}
spring.datasource.driver-class-name=org.postgresql.Driver

# HikariCP settings for cloud databases (Supabase/Render)
# Prevents "connection closed" errors by refreshing connections more frequently
spring.datasource.hikari.maximum-pool-size=5
spring.datasource.hikari.minimum-idle=1
spring.datasource.hikari.max-lifetime=300000
spring.datasource.hikari.connection-timeout=20000
spring.datasource.hikari.keepalive-time=120000

# ----------------------------------------
# FLYWAY DATABASE MIGRATION
# ----------------------------------------
spring.flyway.baseline-on-migrate=true
spring.flyway.locations=classpath:db/migration

# Enable Spring Boot Virtual Threads (Java 21+)
spring.threads.virtual.enabled=true

# ===================================================================
# AI SERVICES (LangChain4j) CONFIGURATION
# ===================================================================

# OpenAI-compatible Chat and Embedding Model Configuration
langchain4j.open-ai.chat-model.base-url=${CHAT_MODEL_BASE_URL:https://dashscope.aliyuncs.com/compatible-mode/v1}
langchain4j.open-ai.chat-model.api-key=${CHAT_MODEL_API_KEY:CHANGE_ME}
langchain4j.open-ai.chat-model.model-name=${CHAT_MODEL_NAME:qwen3-max}
langchain4j.open-ai.chat-model.timeout=60s
langchain4j.open-ai.chat-model.log-requests=true
langchain4j.open-ai.chat-model.log-responses=true

langchain4j.open-ai.streaming-chat-model.base-url=${CHAT_MODEL_BASE_URL:https://dashscope.aliyuncs.com/compatible-mode/v1}
langchain4j.open-ai.streaming-chat-model.api-key=${CHAT_MODEL_API_KEY:CHANGE_ME}
langchain4j.open-ai.streaming-chat-model.model-name=${CHAT_MODEL_NAME:qwen3-max}
langchain4j.open-ai.streaming-chat-model.timeout=60s
langchain4j.open-ai.streaming-chat-model.log-requests=true
langchain4j.open-ai.streaming-chat-model.log-responses=true

langchain4j.open-ai.embedding-model.base-url=${EMBEDDING_MODEL_BASE_URL:https://api.siliconflow.cn/v1}
langchain4j.open-ai.embedding-model.api-key=${EMBEDDING_MODEL_API_KEY:CHANGE_ME}
langchain4j.open-ai.embedding-model.model-name=${EMBEDDING_MODEL_NAME:BAAI/bge-m3}
langchain4j.open-ai.embedding-model.timeout=60s
langchain4j.open-ai.embedding-model.log-requests=true
#langchain4j.open-ai.embedding-model.log-responses=true

# JWT Configuration
jwt.secret=${JWT_SECRET:CHANGE_ME_PLEASE_USE_A_STRONG_SECRET_KEY_MIN_32_CHARS}
jwt.expiration=86400000

# ----------------------------------------
# APPLICATION-SPECIFIC SETTINGS
# ----------------------------------------
# Number of top similar document chunks to retrieve for a query
app.rag.retrieval.top-k=5

# Document chunking settings
app.rag.chunking.size=1000
app.rag.chunking.overlap=300

# Vision model settings (for processing images, charts, scanned pages in PDFs)
app.rag.vision.enabled=${VISION_ENABLED:true}
app.rag.vision.timeout-seconds=${VISION_TIMEOUT:60}
#app.rag.vision.base-url=${VISION_BASE_URL:https://api.siliconflow.cn/v1}
#app.rag.vision.api-key=${VISION_API_KEY:sk-ujpemujkqccrtscjgqwfeuydvloinqppenjvmsolrltbozez}
#app.rag.vision.model-name=${VISION_MODEL_NAME:THUDM/GLM-4.1V-9B-Thinking}
app.rag.vision.base-url=${VISION_BASE_URL:https://zeabur.2morning.cc/v1}
app.rag.vision.api-key=${VISION_API_KEY:CHANGE_ME}
app.rag.vision.model-name=${VISION_MODEL_NAME:gemini-2.0-flash}