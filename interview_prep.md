# RAG 系统面试知识点备忘录

## 1. 混合检索 (Hybrid Search)

### 概念
混合检索是将 **向量检索 (Vector Search)** 和 **关键词检索 (Keyword Search)** 结合起来的一种检索策略。

### 痛点与解决方案
*   **向量检索的痛点**：擅长语义理解（如“番茄炒蛋”匹配“西红柿炒鸡蛋”），但对 **精确匹配**（如特定型号 "AX-9000"、错误码 "Error 503"、生僻词）效果较差，容易产生幻觉或匹配到不相关的近义词。
*   **关键词检索的痛点**：擅长精确匹配，但 **不懂语义**（如搜“手机没电”可能找不到“iPhone 电池耗尽”），容易漏掉相关文档。
*   **混合检索的解法**：同时执行这两种检索，取长补短，通过算法合并结果，显著提升召回率 (Recall)。

### 工作流程
1.  **并行查询**: 用户输入 -> 同时发起向量搜索 (Top-K) 和 关键词搜索 (Top-K)。
2.  **分数归一化**: 将向量相似度（如余弦相似度 0.85）和关键词得分（如 BM25 分数 12.5）统一标准。
3.  **结果融合 (RRF)**: 使用 **倒数排名融合 (Reciprocal Rank Fusion)** 算法，根据文档在两个列表中的**排名**来计算最终得分，重新排序。

---

## 2. PostgreSQL 全文检索 (Full Text Search)

### 核心函数：`to_tsvector`
*   **作用**：将普通文本 (`text`) 转换为专门用于全文检索的数据类型 (`tsvector`)。
*   **处理步骤**：
    1.  **分词 (Tokenization)**：将文本拆分为独立的词元（Token）。支持多语言配置（如 'english', 'simple', 'zh'）。
    2.  **词形还原 (Stemming)**：将词语还原为词根（如 "running" -> "run"），保证不同形态的词能被搜到。
    3.  **停用词移除 (Stop Word Removal)**：去除无意义的高频词（如 "the", "is", "的"），减小索引体积，提高相关性。
*   **结果**：生成包含词元及其位置信息的 `tsvector` 对象。

### 核心索引：GIN (Generalized Inverted Index)
*   **原理**：**倒排索引 (Inverted Index)**。类似于字典的索引页，每个词指向包含该词的所有文档 ID 列表。
*   **优势**：
    *   **极速查询**：直接定位文档，避免全表扫描（Full Table Scan）。
    *   **相比 `LIKE`**：`LIKE '%word%'` 需要全表扫描，效率极低且不支持语义处理；GIN 索引在海量数据下依然保持毫秒级响应。

---

## 3. 重排序 (Re-ranking)

### 概念
在初步检索（Retrieval）之后，引入一个更强大的模型对候选结果进行精细打分和重新排序。

### 为什么需要？
*   **语义漂移**：向量检索为了速度通常使用轻量级模型（如 Bi-Encoder），它只能计算粗略的语义相似度，有时会把“意思相反但语境相似”的文档排在前面。
*   **精度提升**：Re-ranker 模型（如 Cross-Encoder）可以同时看到“问题”和“文档”，进行深度交互计算，判断它们到底有多相关，准确率远高于向量距离。

### 流程
1.  **粗排 (Retrieval)**: 快速从百万级数据中找出 Top-50（使用向量+关键词）。
2.  **精排 (Re-ranking)**: 使用 Re-rank 模型对这 Top-50 进行逐一打分。
3.  **截断**: 取分数最高的 Top-5 给大模型。

---

## 4. 知识图谱增强 (Graph RAG)

### 概念
利用知识图谱 (Knowledge Graph) 来增强 RAG 的推理能力。

### 解决的问题
*   **碎片化**：传统 RAG 将文档切碎，丢失了全局关系（如 A 是 B 的子公司，B 导致了 C）。
*   **多跳推理 (Multi-hop Reasoning)**：用户问“A 公司的子公司的产品的价格是多少？”，传统 RAG 很难关联这层层关系，Graph RAG 可以顺着关系链找到答案。

### 实现方式
*   **提取**: 利用 LLM 从文档中提取实体 (Entity) 和关系 (Relation)。
*   **存储**: 存入图数据库（Neo4j）或关系型数据库。
*   **检索**: 在检索时，不仅查向量，还查询图谱中的关联节点。

---

## 5. 文档切分 (Document Chunking)

### 概念
文档切分是将大型文档（如 PDF、Word、网页等）分解成更小、更易于管理和处理的文本片段（称为“块”或“Chunk”）的过程。

### 为什么在 RAG 中至关重要？
1.  **克服 LLM 上下文窗口限制**：大型语言模型 (LLM) 有严格的输入 token 限制。整个文档通常会超出此限制，无法直接喂给 LLM。切分后，RAG 只需检索并传递最相关的几个 Chunk。
2.  **提高检索相关性**：如果将整个文档作为一个大的 Chunk 嵌入，向量会包含大量噪声信息。更小、更聚焦的 Chunk 能够更精确地捕捉特定主题或信息点，从而使得向量表示更准确，检索时能返回更相关的结果。
3.  **减少推理成本**：传输更小的 Chunk 给 LLM 意味着更少的 token 消耗，从而降低 API 调用成本，并加快推理速度。

### 核心挑战与考虑点
1.  **Chunk 大小 (Chunk Size)**：
    *   **过小**：可能丢失重要的上下文信息，导致 Chunk 过于零碎，LLM 难以理解。例如，一个句子被截断成两部分。
    *   **过大**：Chunk 中包含太多不相关信息，稀释了关键内容，影响检索精度，并可能超出 LLM 上下文。
    *   **通常范围**：根据模型和应用场景，常见 Chunk 大小为 200-1000 个 token。
2.  **Chunk 重叠 (Chunk Overlap)**：
    *   在连续的 Chunk 之间保留一定数量的共享内容（例如，前一个 Chunk 的最后 N 个 token 作为后一个 Chunk 的开头）。
    *   **目的**：确保即使信息位于 Chunk 边界处，LLM 也能获得完整的上下文。
    *   **常见重叠量**：通常为 Chunk 大小的 10%-20%。
3.  **切分策略 (Chunking Strategies)**：
    *   **固定大小切分 (Fixed Size Chunking)**：最简单，按固定字符数或 token 数切分，不考虑文本结构。缺点是可能把句子或段落从中切断。
    *   **递归字符文本切分 (RecursiveCharacterTextSplitter)**：更高级，尝试按照预定义的字符列表（如段落 `\n\n`、行 `\n`、空格 ` `）递归地进行切分，优先保持文本结构的完整性。
    *   **上下文感知切分 (Context-Aware/Semantic Chunking)**：利用文档结构（如标题、子标题、代码块、表格、图片描述）来智能切分，确保每个 Chunk 都包含一个相对完整的逻辑单元。
    *   **文档类型特定切分**：
        *   **PDF**：按页切分，或者更复杂的图像/表格提取（如你的项目中 `ImageProcessor` 和 `TableProcessor` 的功能）。
        *   **Markdown**：按 `#`, `##` 等标题层级切分。
        *   **代码**：按函数、类、代码块切分。
4.  **元数据 (Metadata)**：
    *   为每个 Chunk 附带关键信息，如原始文档 ID、页码、章节、作者、发布日期等。
    *   **作用**：在检索时可以进行过滤（如只搜索特定作者的文档），并为 LLM 提供更多上下文，帮助其理解 Chunk 的来源和背景。

### `qarag` 项目中的实现
你的 `qarag` 项目已经很好地体现了分文档类型切分的思想：
*   `src/main/java/com/example/qarag/ingestion/chunker/DocumentChunker`：定义了统一的文档切分接口。
*   `src/main/java/com/example/qarag/ingestion/chunker/DocumentChunkerFactory`：根据文件类型选择合适的 `Chunker` 实现。
*   `src/main/java/com/example/qarag/ingestion/chunker/PdfChunker`、`WordChunker`、`ExcelChunker`、`MarkdownChunker` 等：各自实现了针对特定文件类型的切分逻辑，包括对图片、表格等的特殊处理。
*   `chunkerName` 字段：你最近添加的 `chunkerName` 字段正是为了记录 Chunk 的来源切分器，方便排查和优化。
